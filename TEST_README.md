# Orchestrator Testing Guide

## Test Scripts

### `test_v0_5_4.py` - Comprehensive v0.5.4 Test

Enhanced test script with complex goals, task dependencies, and directory management.

#### Features

**Complex Test Scenario:**
- 4 core goals (calculator module, test suite, utils module, documentation)
- 7 tasks with dependencies (task-002 depends on task-001, etc.)
- Multiple file types (Python modules, tests, README)
- Pattern matching and command execution verification

**Directory Management:**
- Clear test directory between runs
- Preserve logs for debugging
- Keep test directory for inspection
- Reuse specific test directories

**Comprehensive Validation:**
- Files created in correct location (project root, not .agentic/)
- All required functions/tests present
- Step counting accuracy
- Task dependency ordering
- Failure analysis detection
- Audit system triggering (at step 10)
- Path validation (absolute paths)

#### Usage

**Basic test run (creates temp directory, cleans up after):**
```bash
uv run python test_v0_5_4.py
```

**Keep test directory for inspection:**
```bash
uv run python test_v0_5_4.py --keep
# Output will show: Test directory preserved: /tmp/test-orchestrator-v0.5.4-XXXXX
```

**Use specific test directory:**
```bash
uv run python test_v0_5_4.py --test-dir ./my-test-run
```

**Verbose output (show all orchestrator output):**
```bash
uv run python test_v0_5_4.py --verbose
```

**Increase timeout (default: 300s):**
```bash
uv run python test_v0_5_4.py --timeout 600
```

**Clear existing test directory:**
```bash
uv run python test_v0_5_4.py --clear-only --test-dir ./my-test-run
```

**Clear but keep logs:**
```bash
uv run python test_v0_5_4.py --clear-only --test-dir ./my-test-run --keep-logs
```

#### What Gets Tested

1. **File Creation Location**
   - `calculator.py` with add, subtract, multiply, divide functions
   - `test_calculator.py` with 4+ test functions
   - `utils.py` with reverse_string and capitalize_words functions
   - `test_utils.py` with utils tests
   - `README.md` with Usage and Installation sections

2. **System Behavior**
   - Step counting (every Claude Code call increments step)
   - Workspace paths are absolute
   - Task dependencies respected (task-001 before task-002)
   - No files created in .agentic/ (except logs/config)

3. **v0.5.4 Features**
   - Failure analysis triggers when patterns detected
   - Audit system runs at step 10 (if max_steps allows)
   - MVP-first sequential execution
   - Path validation enforced

#### Test Output Example

```
============================================================
Validation Results
============================================================

✅ Test 1 PASSED: calculator.py with all 4 functions
   Location: /tmp/test-orchestrator-v0.5.4-abc123/calculator.py
   Functions: add, subtract, multiply, divide
✅ Test 2 PASSED: test_calculator.py with 4 test functions
✅ Test 3 PASSED: utils.py with string utility functions
✅ Test 4 PASSED: README.md with documentation sections
✅ Test 5 PASSED: No unexpected files in .agentic/
✅ Test 6 PASSED: Step counting works (max step: 12)
   Total events: 87
   Unique steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
✅ Test 7 PASSED: All workspace paths are absolute (6 checked)
✅ Test 8 PASSED: Task dependencies respected (task-001 before task-002)
   Task execution order: ['task-001', 'task-002', 'task-003', 'task-004', 'task-005']
✅ Test 9 INFO: Failure analysis ran 0 time(s)
✅ Test 10 PASSED: Audit system triggered at step 10

============================================================
Test Summary: 10 passed, 0 failed
============================================================
```

#### Directory Structure After Test

```
test-directory/
├── .agentic/
│   ├── current/
│   │   ├── GOALS.md          # Test goals
│   │   └── TASKS.md          # Test tasks
│   ├── orchestrator.config.yaml
│   └── full_history.jsonl    # Event log
├── calculator.py             # Generated by orchestrator
├── test_calculator.py        # Generated by orchestrator
├── utils.py                  # Generated by orchestrator
├── test_utils.py             # Generated by orchestrator
└── README.md                 # Generated by orchestrator
```

#### Workflow Examples

**Quick test:**
```bash
uv run python test_v0_5_4.py
```

**Debug a test failure:**
```bash
# Run with preserved directory
uv run python test_v0_5_4.py --keep --test-dir ./debug-run --verbose

# Inspect generated files
ls -la ./debug-run/
cat ./debug-run/calculator.py

# Check event log for issues
tail -20 ./debug-run/.agentic/full_history.jsonl | jq '.payload'

# Clear and re-run
uv run python test_v0_5_4.py --clear-only --test-dir ./debug-run
uv run python test_v0_5_4.py --test-dir ./debug-run --verbose
```

**Long-running test (to trigger audit at step 10):**
```bash
# Modify max_steps in generated config to be higher if needed
uv run python test_v0_5_4.py --keep --timeout 600
```

### `test_v0_5_0.py` - Original Simple Test

Basic test with single goal/task. Simpler but less comprehensive.

**Run:**
```bash
uv run python test_v0_5_0.py
```

**Use case:** Quick validation that basic functionality works.

## Continuous Integration

Add to CI pipeline:

```yaml
# .github/workflows/test.yml
- name: Test Orchestrator v0.5.4
  run: |
    uv run python test_v0_5_4.py --timeout 300
  timeout-minutes: 10
```

## Troubleshooting

**Test times out:**
- Increase timeout: `--timeout 600`
- Check if Claude Code CLI is responsive
- Review logs in preserved test directory

**Test fails validation:**
- Run with `--verbose` to see full output
- Use `--keep` to inspect generated files
- Check event log for errors: `.agentic/full_history.jsonl`

**Audit test fails (Test 10):**
- Check if max_step reached 10: `jq '.step' full_history.jsonl | sort -u`
- Increase max_steps in config if needed
- Audit only runs at step 10, 20, 30, etc.

**Task dependency test fails:**
- Check task execution order in event log
- Verify TASKS.md has "Depends: task-XXX" lines
- Check if tasks completed or failed

## Best Practices

1. **Always use `--keep` when debugging** to preserve test artifacts
2. **Use specific test directory** for reproducible debugging
3. **Clear between runs** to ensure clean state
4. **Check event logs** for detailed execution trace
5. **Run verbose mode** when investigating failures
